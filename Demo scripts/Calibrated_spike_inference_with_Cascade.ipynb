{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HelmchenLabSoftware/Cascade/blob/master/Demo%20scripts/Calibrated_spike_inference_with_Cascade.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECkMdA5pMRSY"
      },
      "source": [
        "# CASCADE\n",
        "\n",
        "## Calibrated spike inference from calcium imaging data using deep networks\n",
        "Written and maintained by [Peter Rupprecht](https://github.com/PTRRupprecht) and [Adrian Hoffmann](https://github.com/AdrianHoffmann) from the [Helmchen Lab](https://www.hifo.uzh.ch/en/research/helmchen.html).\n",
        "The project started as a collaboration of the Helmchen Lab and the [Friedrich Lab](https://www.fmi.ch/research-groups/groupleader.html?group=119). Feedback goes to [Peter Rupprecht](mailto:p.t.r.rupprecht+cascade@gmail.com).\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "This colaboratory notebook runs on servers in the cloud. It uses an algorithm based on deep networks for spike inference (CASCADE, described in this **[Resource Article](https://www.nature.com/articles/s41593-021-00895-5)** published in Nature Neuroscience). Here, you can test the algorithm and use it without any installation on your computer. You just have to sequentially **press the play buttons (\"Run cell\")** on the left of each box, and the code will be executed.\n",
        "\n",
        "* If you want to **see the algorithm in action**, just execute the cells without any modifications. Enjoy!\n",
        "\n",
        "* If you want to **upload your own data**, make predictions and download the saved files, you have to modify the variable names and follow the instructions. Usually no or very little modifications of the code is required.\n",
        "\n",
        "* If you want to integrate CASCADE into **your local data analysis pipeline**, we suggest you take a look at the [Github repository](https://github.com/HelmchenLabSoftware/Calibrated-inference-of-spiking).\n",
        "\n",
        "At the end of the notebook, there is a FAQ which answers the most urgent questions (e.g., how do I interpret the results correctly?).\n",
        "\n",
        "Let's jump in!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOWWhpFGk7lA"
      },
      "source": [
        "##1. Download repository into the Colab Notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfupSpg7FtpN",
        "outputId": "58fe953e-bfae-4773-e740-8426cabd0212"
      },
      "outputs": [],
      "source": [
        "#@markdown The Github repository with all custom functions, the ground truth datasets and the pretrained models is copied to the environment of this notebook. This will take a couple of seconds.\n",
        "\n",
        "#@markdown *Note: You can check the code underlying each cell by double-clicking on it.*\n",
        "\n",
        "import os\n",
        "\n",
        "# If in Colab and not yet downloaded, download GitHub repository and change working directory\n",
        "if os.getcwd() == '/content':\n",
        "    !git clone https://github.com/HelmchenLabSoftware/Cascade\n",
        "    os.chdir('Cascade')\n",
        "\n",
        "# If executed as jupyter notebook on own computer, change to parent directory for imports\n",
        "if os.path.basename( os.getcwd() ) == 'Demo scripts':\n",
        "    %cd ..\n",
        "    print('New working directory:', os.getcwd() )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBMThw3clDu4"
      },
      "source": [
        "##2. Import required python packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "u-cs8Jze8MpX"
      },
      "outputs": [],
      "source": [
        "#@markdown Downloads packages from public repository, and packages from Cascade.\n",
        "\n",
        "%%capture\n",
        "!pip install ruamel.yaml\n",
        "\n",
        "# standard python packages\n",
        "import os, warnings\n",
        "import glob\n",
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "import matplotlib.pyplot as plt\n",
        "import ruamel.yaml as yaml\n",
        "yaml = yaml.YAML(typ='rt')\n",
        "\n",
        "# cascade2p packages, imported from the downloaded Github repository\n",
        "from cascade2p import checks\n",
        "checks.check_packages()\n",
        "from cascade2p import cascade # local folder\n",
        "from cascade2p.utils import plot_dFF_traces, plot_noise_level_distribution, plot_noise_matched_ground_truth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19xLRfZXlG3z"
      },
      "source": [
        "##3. Define the function to load ﾎ認/F traces\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "slzhhQLd8YeP"
      },
      "outputs": [],
      "source": [
        "#@markdown ﾎ認/F traces must be saved as \\*.npy-files (for Python) or \\*.mat-files (for Matlab/Python) as a single large matrix named **`dF_traces`** (neurons x time). ﾎ認/F values of the input should be numeric, not in percent (e.g. 0.5 instead of 50%). For different input formats, the code in this box can be modified (it\\'s not difficult).\n",
        "\n",
        "def load_neurons_x_time(file_path):\n",
        "    \"\"\"Custom method to load data as 2d array with shape (neurons, nr_timepoints)\"\"\"\n",
        "\n",
        "    if file_path.endswith('.mat'):\n",
        "      traces = sio.loadmat(file_path)['dF_traces']\n",
        "\n",
        "    elif file_path.endswith('.npy'):\n",
        "      traces = np.load(file_path, allow_pickle=True)\n",
        "      # if saved data was a dictionary packed into a numpy array (MATLAB style): unpack\n",
        "      if traces.shape == ():\n",
        "        traces = traces.item()['dF_traces']\n",
        "\n",
        "    else:\n",
        "      raise Exception('This function only supports .mat or .npy files.')\n",
        "\n",
        "    print('Traces standard deviation:', np.nanmean(np.nanstd(traces,axis=1)))\n",
        "    if np.nanmedian(np.nanstd(traces,axis=1)) > 2:\n",
        "      print('Fluctuations in dF/F are very large, probably dF/F is given in percent. Traces are divided by 100.')\n",
        "      return traces/100\n",
        "    else:\n",
        "        return traces\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9yjbje7lQIA"
      },
      "source": [
        "##4. Select dataset, indicate frame rate and load ﾎ認/F traces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKyE8JVV8fMg",
        "outputId": "728dfc63-c761-4353-ebba-179cda26f355"
      },
      "outputs": [],
      "source": [
        "#@markdown If you are testing the script, you can leave everything unchanged. If you want to apply the algorithm to your own data, you have to upload your data first. The paragraph above tells you how to format and name the file. You can do this by clicking on the **folder symbol (\"Files\")** on the left side of the Colaboratory notebook. Next, indicate the path of the uploaded file in the variable **`example_file`**. Finally, indicate the sampling rate of your recordings in the variable **`frame_rate`**.\n",
        "\n",
        "example_file = \"Example_datasets/Allen-Brain-Observatory-Visual-Coding-30Hz/Experiment_552195520_excerpt.mat\" #@param {type:\"string\"}\n",
        "\n",
        "frame_rate = 30 #@param {type:\"number\"}\n",
        "\n",
        "try:\n",
        "\n",
        "  traces = load_neurons_x_time( example_file )\n",
        "  print('Number of neurons in dataset:', traces.shape[0])\n",
        "  print('Number of timepoints in dataset:', traces.shape[1])\n",
        "\n",
        "except Exception as e:\n",
        "\n",
        "  print('\\nSomething went wrong!\\nEither the target file is missing, in this case please provide the correct location.\\nOr your file is not yet completely uploaded, in this case wait until the upload is completed.\\n')\n",
        "\n",
        "  print('Error message: '+str(e))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWpOOA_dlUmp"
      },
      "source": [
        "##5. Plot distribution of noise levels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "DHG3cIw4DwNI",
        "outputId": "0fa60609-f447-4b81-b271-5b49695d8ff8"
      },
      "outputs": [],
      "source": [
        "#@markdown For each neuron in the loaded dataset, the noise level will be computed and the distribution across neurons will be shown.\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [12, 5]\n",
        "\n",
        "noise_levels = plot_noise_level_distribution(traces,frame_rate)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO8m4QpulXhS"
      },
      "source": [
        "##6. Plot randomly selected calcium traces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n5_jjeAGD4AF",
        "outputId": "07c65115-6ce1-4829-996a-e98923802862"
      },
      "outputs": [],
      "source": [
        "#@markdown Plotting random traces helps to check whether the data have been loaded correctly. If you want to plot specific instead of randomly selected neurons, modify the variable **`neuron_indices`** accordingly.\n",
        "\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [13, 13]\n",
        "\n",
        "#np.random.seed(3952)\n",
        "neuron_indices = np.random.randint(traces.shape[0], size=16)\n",
        "time_axis = plot_dFF_traces(traces,neuron_indices,frame_rate)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TasQNTjQlbt1"
      },
      "source": [
        "##7. Select pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGPusfo-y9_d",
        "outputId": "a483cce8-c806-4c85-83dd-69eaca692a35"
      },
      "outputs": [],
      "source": [
        "#@markdown Get list of the names of available models.\n",
        "\n",
        "\n",
        "cascade.download_model( 'update_models',verbose = 1)\n",
        "\n",
        "yaml_file = open('Pretrained_models/available_models.yaml')\n",
        "X = yaml.load(yaml_file)\n",
        "list_of_models = list(X.keys())\n",
        "print('\\n List of available models: \\n')\n",
        "for model in list_of_models:\n",
        "  print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cObwxWaB8i3f",
        "outputId": "6ad8b932-2ec3-47a1-ef6b-b2ac05477a4d"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@markdown Select (from the list above) and download the model that fits to your dataset (frame rate, training data; see FAQ for more details) and assign to variable **`model_name`**.\n",
        "\n",
        "model_name = \"Global_EXC_30Hz_smoothing25ms_causalkernel\" #@param {type:\"string\"}\n",
        "\n",
        "cascade.download_model( model_name,verbose = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bzFhrlslkOh"
      },
      "source": [
        "##8. Predict spike rates from ﾎ認/F traces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8uu8p_XETZ5",
        "outputId": "14441952-8de0-48e4-e1cf-73ddbde40b75"
      },
      "outputs": [],
      "source": [
        "#@markdown If this takes too long, make sure that the GPU runtime is activated (*Menu > Runtime > Change Runtime Type*).\n",
        "\n",
        "total_array_size = traces.itemsize*traces.size*64/1e9\n",
        "\n",
        "# If the expected array size is too large for the Colab Notebook, split up for processing\n",
        "if total_array_size < 10:\n",
        "\n",
        "  spike_prob = cascade.predict( model_name, traces, verbosity=1 )\n",
        "\n",
        "# Will only be use for large input arrays (long recordings or many neurons)\n",
        "else:\n",
        "\n",
        "  print(\"Split analysis into chunks in order to fit into Colab memory.\")\n",
        "\n",
        "  # pre-allocate array for results\n",
        "  spike_prob = np.zeros((traces.shape))\n",
        "  # nb of neurons and nb of chuncks\n",
        "  nb_neurons = traces.shape[0]\n",
        "  nb_chunks = int(np.ceil(total_array_size/10))\n",
        "\n",
        "  chunks = np.array_split(range(nb_neurons), nb_chunks)\n",
        "  # infer spike rates independently for each chunk\n",
        "  for part_array in range(nb_chunks):\n",
        "    spike_prob[chunks[part_array],:] = cascade.predict( model_name, traces[chunks[part_array],:] )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGPzJMJ3mCCM"
      },
      "source": [
        "##9. Plot randomly selected example predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "H7SKGRpP8oRe",
        "outputId": "42e4c93b-545c-4183-d6a2-e412e7793532"
      },
      "outputs": [],
      "source": [
        "#@markdown By default plots a set of 16 randomly chosen neuronal traces (first seconds). The dF/F traces are shown in blue, the inferred spike probability is plotted in orange (shifted downwards by 1 for better visibility).\n",
        "\n",
        "nb_neurons = 16\n",
        "\n",
        "neuron_indices = np.random.randint(traces.shape[0], size=nb_neurons)\n",
        "time_axis = plot_dFF_traces(traces,neuron_indices,frame_rate,spike_prob,y_range=(-1.5, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F0puCOmmW10"
      },
      "source": [
        "##10. Plot noise-matched examples from the ground truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "p4EEpDIJ8ndM"
      },
      "outputs": [],
      "source": [
        "#@markdown Plots randomly drawn excerpts from the ground truth, re-sampled at the same frame rate and noise level as a typical recording of the test dataset. The resampled dF/F signal is shown in blue. The true spike rate convolved with a smoothing kernel is shown in orange (shifted downward by 1 for better visibility).\n",
        "\n",
        "#@markdown This allows to directly compare **data quality** and **possible artifacts** of training dataset (ground truth) and test dataset (your calcium imaging data).\n",
        "\n",
        "#@markdown Repeatedly execute this cell to plot new examples.\n",
        "\n",
        "median_noise = np.round(np.maximum(2,np.median(noise_levels)))\n",
        "nb_traces = 16\n",
        "duration = max(time_axis) - 64/frame_rate # seconds\n",
        "plot_noise_matched_ground_truth( model_name, median_noise, frame_rate, nb_traces, duration )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFNGKA-omcKJ"
      },
      "source": [
        "##11. Save predictions to output file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mcgvh1Ma8mBN"
      },
      "outputs": [],
      "source": [
        "#@markdown By default saves as variable **`spike_prob`** both to a *.mat-file and a *.npy-file. You can uncomment the file format that you do not need or leave it as it is.\n",
        "\n",
        "folder = os.path.dirname(example_file)\n",
        "file_name = 'predictions_' + os.path.splitext( os.path.basename(example_file))[0]\n",
        "save_path = os.path.join(folder, file_name)\n",
        "\n",
        "# save as mat file\n",
        "sio.savemat(save_path+'.mat', {'spike_prob':spike_prob})\n",
        "\n",
        "# save as numpy file\n",
        "np.save(save_path, spike_prob)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7bQRPs2sGiT"
      },
      "source": [
        "# FAQ\n",
        "## Frequently Asked Question\n",
        "<a id='FAQ'></a>\n",
        "Everything you need to know to properly use the above code, to correctly interpret the results, and much more.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J6LAjXTr-0l"
      },
      "source": [
        "#### What does the output of the algorithm mean?\n",
        "\n",
        ">The output **spike_prob** is the _expected number of spikes_ in this time bin, at the same resolution as the original calcium recording. This metric is also called _spike probability_ for brevity in the paper and elsewhere. If you sum over the trace in time, you will get the estimated **number of spikes**. If you multiply the trace with the frame rate, you will get an estimate of the instantaneous **spike rate**. Spike probability and spike rates can therefore be converted by multiplication with the frame rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tXN9GYU7Kc9"
      },
      "source": [
        "#### Can **spike_prob** be larger than 1?\n",
        "\n",
        ">Yes. As described above (\"What does the output of the algorithm mean?\"), the output of the algorithm is strictly speaking not a probability and therefore not restricted to values between 0 and 1. A value >1 indicates that the estimated number of spikes in the time bin is larger than 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJe2vmrmwdVx"
      },
      "source": [
        "#### How large would a single spike be?\n",
        ">This depends on your **frame rate** (Hz) and on the **smoothing** (milliseconds) of your model. Use the following script to compute how the inferred spike probability shape would look like for a single isolated spike for given parameters.\n",
        ">\n",
        ">**Smoothing** is the standard deviation of the Gaussian used to smooth the ground truth spike rate before it is used for training. In the file name of a pretrained model, the smoothing parameter is indicated. Read below for more details.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjQRicRSsOMx",
        "outputId": "12bf4420-6ba8-456f-eeb9-a3495f918e42"
      },
      "outputs": [],
      "source": [
        "from scipy.ndimage.filters import gaussian_filter\n",
        "import numpy as np\n",
        "\n",
        "sampling_rate = 30 #@param {type:\"number\"}\n",
        "smoothing = 50 #@param {type:\"number\"}\n",
        "\n",
        "# find out empirically  how large a single AP is\n",
        "single_spike = np.zeros(1001,)\n",
        "single_spike[501] = 1\n",
        "single_spike_smoothed = gaussian_filter(single_spike.astype(float), sigma=smoothing/1e3*sampling_rate)\n",
        "\n",
        "gaussian_amplitude = np.round(np.max(single_spike_smoothed)*1000)/1000\n",
        "\n",
        "gaussian_width = np.round(2*np.sqrt(2*np.log(2))*smoothing/1e3*100)/100\n",
        "\n",
        "\n",
        "print('A single spike in the predictions will have an amplitude of '+str(gaussian_amplitude)+' and a width (FWHM) of '+str(gaussian_width)+' seconds.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8JPuq0fvtkr"
      },
      "source": [
        "#### How precise and good are my predictions?\n",
        "\n",
        ">This depends mainly on the **shot noise level** of your dataset. If you want to compute how well the chosen model generalizes to unseen data for a given noise level, check out the Github repository and use [the demo script](https://github.com/HelmchenLabSoftware/Cascade/blob/master/Demo%20scripts/Demo_benchmark_model.py) which computes the performance of a given model.\n",
        ">\n",
        ">To get a good idea about the quality of predictions to unseen data, check out **Figure 3** and the associated discussion in the [paper](https://www.nature.com/articles/s41593-021-00895-5)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pY3QFsBwzXn"
      },
      "source": [
        "#### Why is the output of the algorithm a probability, why not discrete spikes?\n",
        "\n",
        ">Good question! We think that providing spike times instead of spike rates or spiking probabilities is misleading, since it suggests a false precision and certainty of the spiking estimates. In addition, we found (**Fig. S7** in the [paper](https://www.nature.com/articles/s41593-021-00895-5)) that single-spike precision could not achieved with any of the ground truth datasets.\n",
        ">\n",
        ">However, for some cases, discrete spikes still might be a good approach. We provide a Python function that converts the spiking probability into the most likely underlying discrete spikes (**[demo](https://github.com/HelmchenLabSoftware/Cascade/blob/master/Demo%20scripts/Demo_discrete_spikes.py)** on Github).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iprQt4iDxrPw"
      },
      "source": [
        "#### Why are the first and last datapoints of the predictions NaNs?\n",
        "\n",
        ">The deep network uses a window that looks at the calcium trace around the current time point to better understand the context of the current time point. For the first and last points in time, the network is unable to look into the environment and therefore gives back NaNs. If the window size of the network is 64 datapoints (which is the default), the first and last 32 time points will be NaNs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZb46zWiyRg3"
      },
      "source": [
        "#### I get a certain noise level for my recordings. What is good or bad?\n",
        "\n",
        ">For an illustration of different noise levels, check out Extended Data Fig. 3 in the [paper](https://www.nature.com/articles/s41593-021-00895-5). To give an example, the Allen Brain Observatory Visual Coding dataset is of very high imaging quality, with noise levels around **1, which is very good** (unit: $\\small \\%ﾂｷs^{-1/2}$ ). A noise level of **3-4 is still decent**, especially for population imaging with many neurons. Noise levels **above 5 indicates rather poor signal** levels. For a definition of the noise level, check out the Methods of the preprint.\n",
        ">\n",
        ">However, even for excellent shot noise levels, the recording quality can be bad due to bad imaging resolution, **neuropil contamination** and, most importantly, **movement artifacts**. See Extended Data Fig. 5 in the [paper](https://www.nature.com/articles/s41593-021-00895-5) and the associated text as well as the Discussion for more details.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92Pe-TACmz61"
      },
      "source": [
        "#### How do I select an appropriate model for my data?\n",
        "\n",
        "> Each model is trained on a resampled ground truth dataset, as described in the preprint. The training dataset is resampled at the desired frame rate and at multiple noise levels. The model automatically chooses the model with matching noise-levels for each neuron. You only have to select the correct frame rate (which is indicated in the model name).\n",
        ">\n",
        ">If you do not have a specific ground truth for your dataset, it is typically best (see Fig. 3 and the associated discussion in the [paper](https://www.nature.com/articles/s41593-021-00895-5)) to use a model that has been trained on all available datasets (called 'Global EXC Model').\n",
        ">\n",
        ">There are two additional model specifications that you can choose, \"causal\" kernels and \"smoothing\". The choice of these specifications does not make a model better or worse, but better or less well suited for your needs. See the following two questions!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRrC5kRxoIVD"
      },
      "source": [
        "#### What does the **smoothing** parameter for the models mean?\n",
        "\n",
        "> The ground truth which has been used to train the model has been slightly smoothed with a Gaussian kernel. This is a processing step which helps the deep network to learn quicker and more reliably. However, this also means that the predictions will be smoothed in a similar fashion. How to choose these parameters optimally?\n",
        ">\n",
        "> From our experience, at a frame rate of 7.5 Hz, a smoothing kernel with standard deviation of 200 ms is appropriate; for nicely visible transients, also a value of 100 or 50 ms can be tried out, and we have had cases where this was the most satisfying choice of parameters. At 30 Hz, a smoothing kernel of 50 ms works well, but a smoothing kernel of 25 ms could be tried as well if the data quality is good and if one wants to avoid temporally smooth predictions. If the calcium imaging quality is not ideal, it can make sense to increase the smoothing kernel standard deviation. In the end, it is always a trade-off between reliability and optimal learning (more smoothing) and temporal precision (less smoothing of the ground truth). The impact of temporal smoothing on the quality of the inference is discussed in Extended Data Fig. 9 in the [paper](https://www.nature.com/articles/s41593-021-00895-5).\n",
        ">\n",
        "> However, if you use our suggested default specifications and your results look useful, you should be good!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45s1RUbGpvWA"
      },
      "source": [
        "#### What does the \"causal\" mean for some of the models?\n",
        "\n",
        "> By default, the ground truth is smoothed symmetrically in time. This means, also the predicted spike probabilities are symetrically distributed in time around the true time point. In some cases, this can be a problem because this predicts non-zero neuronal spiking probability before the calcium event had even started. Especially when you want to analyze stimulus-triggered activity patterns, this is an important issue and a common problem for all deconvolution algorithms.\n",
        ">\n",
        "> However, if the ground truth is smoothed not with a symmetric Gaussian but with a smooth causal kernel, this limitation can be circumvented (discussed in detail in Fig. S12 in the [paper](https://www.nature.com/articles/s41593-021-00895-5)), and spiking activity is almost exclusively assigned to time points after the calcium event started. It must be noted that this reliable causal re-assignment of activity works well for high-quality datasets, but in case of higher noise levels, any deconvolution algorithm will assign activity to non-causal time points. Good to keep in mind when you interpret your results!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyN_UyhhrSpA"
      },
      "source": [
        "#### None of the models is good for me. What can I do?\n",
        "\n",
        "> First of all, is this really true? For example, if you have recorded at 30.5 Hz, you can also use a model trained at 30 Hz imaging rates. A deviation by less than 5\\% of the imaging rate is totally okay in our experience!\n",
        ">\n",
        "> If however you want to use an entirely different model, for example a model trained at a sampling rate of 2 Hz, or a model only trained with a specific ground truth dataset, you have two options. 1) You go to the [Github page](https://github.com/HelmchenLabSoftware/Cascade) and follow the instructions on how to train you own model. This can be done even without GPU-support, but it will take some time (on the other hand, you only have to do this once). 2) You contact us via [e-Mail](mailto:p.t.r.rupprecht+cascade@gmail.com) and tell us what kind of model you would like to have. We will train it for you and upload it to our repository. Not only you, but everybody will then be able to use it further on.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzWdFHvisp0I"
      },
      "source": [
        "#### I have my own ground truth dataset. How can I use it?\n",
        "\n",
        "> You have two options.\n",
        ">\n",
        "> Either you process the data yourself. You can inspect the ground truth datasets, which consist of Matlab structs saved as a file for each neuron from the [ground truth](https://github.com/HelmchenLabSoftware/Cascade/tree/master/Ground_truth). If you process your ground truth recordings into the same format, you can use it as a training set and train the model yourself. Detailed instructions are provided in the [Github repository](https://github.com/HelmchenLabSoftware/Cascade).\n",
        ">\n",
        "> Or you can contact us, and we help to process your dataset if it meets certain quality standards. We can process raw calcium and ephys recordings, but if you can provide extracted dF/F traces and spike times this would of course be even better. Yes, we will do the work for you. But only under the condition that the processed dataset will then be integrated into the published set of ground truth datasets, where it is openly accessible to everybody. Please get in touch with us to discuss options on how to get credit for the recording of the dataset, which we will discuss case by case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PSTxhHkvLc6"
      },
      "source": [
        "#### I want to use my own ground truth dataset, but I don't want to share it.\n",
        "\n",
        "> As mentioned, you can process the ground truth dataset yourself. However, we will only help you with the dataset is made public afterwards.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHmW_G6bvcYC"
      },
      "source": [
        "#### Can I use Cascade also locally, *e.g.*, within [CaImAn](https://github.com/flatironinstitute/CaImAn), or in my own pipeline?\n",
        "\n",
        "> Sure! We have done this ourselves with CaImAn and our custom analysis pipelines. Your starting point to do this will not be this Colaboratory Notebook, but rather the [Github repository](https://github.com/HelmchenLabSoftware/Cascade). Check out the demo Python scripts (*.py). They are very easy to understand and will show you which functions you have to use and how. If you have successfully used this Colaboratory Notebook, understanding the demo scripts will be a piece of cake."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hp_yBrsPWXW8"
      },
      "source": [
        "#### Can I use Cascade as well for endoscopic 1p calcium imaging data?\n",
        "\n",
        "> One of the key features of Cascade is that it infers absolute spike rates. To achieve this, it is necessary that dF/F values extracted from neuronal ROIs are approximately correct. For endoscopic 1p calcium imaging data, the background fluorescence is typically extremely high, and complex methods for subtraction of global or local background activity are used (e.g., by [CNMF-E](https://elifesciences.org/articles/28728)). As also discussed in the CNMF-E paper, extraced traces therefore cannot be properly transformed into dF/F values. We therefore do not recommend Cascade for the deconvolution of this kind of dataset. A purely linear deconvolution algorithm that does not reflect the absolute scaling of the input would be a better choice in such a case, if deconvolution is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xew6wlgvwnOh"
      },
      "source": [
        "#### I would like to look at the ground truth data.\n",
        "\n",
        "> We actually recommend this to anybody who is doing calcium imaging at cellular resolution. Looking at the ground truth data of simultaneous calcium and juxtacellular recording is very enlightening. In the [Github repository](https://github.com/HelmchenLabSoftware/Cascade), we have written an interactive tool to conveniently visualize all ground truth datasets, it is available as a [Colaboratory Notebook](https://colab.research.google.com/github/HelmchenLabSoftware/Cascade/blob/master/Demo%20scripts/Explore_ground_truth_datasets.ipynb).\n",
        ">\n",
        "> We recommend to browse through these datasets to any person doing calcium imaging.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asQ-oC_QvuTx"
      },
      "source": [
        "#### Which reference should I cite?\n",
        "\n",
        "\n",
        "> Please cite the [paper](https://www.nature.com/articles/s41593-021-00895-5) as a reference for Cascade:\n",
        ">\n",
        "> Rupprecht P, Carta S, Hoffmann A, Echizen M, Blot A, Kwan AC, Dan Y, Hofer SB, Kitamura K, Helmchen F\\*, Friedrich RW\\*, *A database and deep learning toolbox for noise-optimized, generalized spike inference from calcium imaging*, Nature Neuroscience (2021).\n",
        ">\n",
        "> (\\* = co-senior authors)\n",
        ">\n",
        ">.\n",
        ">\n",
        "> If you use the respective ground truth datasets directly, please also refer to the original papers and the associated dataset:\n",
        ">\n",
        "> Rupprecht P, Carta S, Hoffmann A, Echizen M, Blot A, AC Kwan, Dan Y, Hofer SB, Kitamura K, Helmchen F\\*, Friedrich RW\\*, *A database and deep learning toolbox for noise-optimized, generalized spike inference from calcium imaging*, Nature Neuroscience (2021), for datasets \\#3-8, \\#19 and \\#27.\n",
        ">\n",
        "> Schoenfeld G, Carta S, Rupprecht P, Ayaz A, Helmchen F, *In vivo calcium imaging of CA3 pyramidal neuron populations in adult mouse hippocampus*, eNeuro (2021), for dataset \\#18.\n",
        ">\n",
        "> Chen TW, Wardill TJ, Sun Y, Pulver SR, Renninger SL, Baohan A, Schreiter ER, Kerr RA, Orger MB, Jayaraman V, Looger LL. *Ultrasensitive fluorescent proteins for imaging neuronal activity*, Nature (2013), for datasets \\#9 and \\#14.\n",
        ">\n",
        "> Huang L, Ledochowitsch P, Knoblich U, Lecoq J, Murphy GJ, Reid RC, de Vries SE, Koch C, Zeng H., Buice MA, Waters J, Lu Li, *Relationship between simultaneously recorded spiking activity and fluorescence signal in GCaMP6 transgenic mice*, eLife (2021), for datasets \\#10, \\#11, \\#12 and \\#13.\n",
        ">\n",
        "> Berens P, et al. *Community-based benchmarking improves spike rate inference from two-photon calcium imaging data*, PLoS Comp Biol (2018), for datasets \\#1, \\#15, \\#16.\n",
        ">\n",
        "> Akerboom J, Chen TW, Wardill TJ, Tian L, Marvin JS, Mutlu S, Calderﾃｳn NC, Esposti F, Borghuis BG, Sun XR, Gordus A. *Optimization of a GCaMP calcium indicator for neural activity imaging*, J Neuroscience (2012), for dataset \\#17.\n",
        ">\n",
        "> Bethge P, Carta S, Lorenzo DA, Egolf L, Goniotaki D, Madisen L, Voigt FF, Chen JL, Schneider B, Ohkura M, Nakai J. *An R-CaMP1.07 reporter mouse for cell-type-specific expression of a sensitive red fluorescent calcium indicator*, PloS ONE (2017), for dataset \\#19.\n",
        ">\n",
        "> Tada M, Takeuchi A, Hashizume M, Kitamura K, Kano M. *A highly sensitive fluorescent indicator dye for calcium imaging of neural activity in vitro and in vivo*, EJN (2014), for dataset \\#3.\n",
        ">\n",
        "> Dana H, Mohar B, Sun Y, Narayan S, Gordus A, Hasseman JP, Tsegaye G, Holt GT, Hu A, Walpita D, Patel R. *Sensitive red protein calcium indicators for imaging neural activity*, Elife (2016), for datasets \\#20 and \\#21.\n",
        ">\n",
        "> Khan AG, Poort J, Chadwick A, Blot A, Sahani M, Mrsic-Flogel TD, Hofer SB. *Distinct learning-induced changes in stimulus selectivity and interactions of GABAergic interneuron classes in visual cortex*, Nature Neuroscience (2018), for datasets \\#24-26.\n",
        ">\n",
        "> Kwan AC, Dan Y. *Dissection of cortical microcircuits by single-neuron stimulation in vivo*, Current Biology (2012), for datasets \\#2 and \\#22-23.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "name": "Calibrated spike inference with Cascade.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
